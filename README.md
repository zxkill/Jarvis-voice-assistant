# Jarvis-Pi — офлайн голосовой ассистент для Raspberry Pi

Jarvis-Pi — русскоязычный офлайн голосовой ассистент и эмоциональный робот. Он работает на Raspberry Pi, поддерживает локальное распознавание речи и синтез, интегрируется с Ollama для запуска LLM и выводит состояние на OLED через ESP32. Все вычисления происходят локально, что обеспечивает приватность и минимальные задержки.

## Возможности

- Активация по фразе «Джарвис» (Vosk)
- Натуральный синтез речи Piper
- Предварительная очистка и нормализация текста для синтеза речи
  (удаление лишних символов, корректное произношение чисел)
- Горячая перезагрузка скиллов
- Система эмоций valence–arousal и проактивные подсказки
- Управление через Telegram‑бот
 - Отображение статуса в консоли или на M5Stack Core ESP32 с OLED
- Интеграция с локальной LLM через Ollama
- Гибкий движок LLM с профилями `light` и `heavy`
- Локальное хранение краткосрочного и долговременного контекста
- Автоповорот и обзор камеры при отсутствии пользователя

## Требования к оборудованию

- Raspberry Pi 4 или новее
- USB‑микрофон и динамик
- Подключение к интернету для Telegram и LLM (опционально)
 - Встроенная или USB‑камера
 - (Необязательно) M5Stack Core ESP32 с OLED — по умолчанию информация выводится в консоль

## Установка

1. Установите Raspberry Pi OS и обновите систему.
2. Клонируйте репозиторий и установите зависимости:

```bash
git clone https://github.com/.../Jarvis-voice-assistant.git
cd Jarvis-voice-assistant
pip install -r requirements.txt
```

3. Скачайте модели Vosk и Piper в каталог `models/`.
4. Заполните `config.ini` и запустите ассистента:

```bash
python start.py
```

## Настройка локальной LLM

Модуль `core/llm_engine.py` отправляет запросы к серверу Ollama по
современному эндпоинту `/v1/chat/completions`. Если он недоступен,
используется запасной вариант `/api/generate`, что сохраняет совместимость с
устаревшими версиями сервиса. Поддерживаются профили `light` и `heavy`,
выбирающие баланс между скоростью и качеством. HTTP‑вызов выполняется с
параметром `stream=false`, поэтому сервер возвращает единый JSON‑ответ и его
легко парсить. Каждый запрос сопровождается `trace_id`, а реплики
пользователя и модели сохраняются в краткосрочную (`context/short_term.py`)
и долговременную память (`context/long_term.py`).

## Переключение дисплея

По умолчанию ассистент использует консоль как «виртуальный» экран. Чтобы вернуть вывод на M5Stack Core ESP32, измените секцию `DISPLAY` в `config.ini`:

```ini
[DISPLAY]
driver = serial
```

После этого прошейте и подключите устройство:

```bash
cd JarvisM5
pio run -t upload
```

## Автосканирование камеры

Если в кадре долго нет лица, ассистент включает плавное **автосканирование камеры** и затем «засыпает». Чтобы функция работала, активируйте модуль присутствия в `config.ini`:

```ini
[PRESENCE]
enabled = true
```

Камера поочерёдно оглядывает комнату, а появившийся человек или голосовая команда моментально возвращают её в рабочий режим.

## Создание своих скиллов

Добавьте Python‑файл в `skills/`:

```python
PATTERNS = ["привет", "здравствуй"]

def handle(text: str) -> str:
    return "Привет, создатель!"
```

Скилл подхватится автоматически после перезапуска.

## Тестирование

```bash
pytest --cov
```

## Roadmap и лицензия

- v0.5: ESP32 + OLED по Serial
- v1.0: интеграция с ROS и SLAM

Проект распространяется по лицензии MIT.

Ключевые слова: voice assistant, Raspberry Pi, offline, Telegram bot, LLM, M5Stack.
