# Jarvis-Pi — голосовой ассистент и «мозг» для персонального робота

> Русскоязычный оффлайн-ассистент с горячей перезагрузкой плагинов, поддержкой локальной LLM через Ollama, выводом состояния на OLED через ESP32 по USB‑Serial и расширяемым фреймворком скиллов.

---

## Содержание

1. [Возможности](#возможности)
2. [Структура проекта](#структура-проекта)
3. [Аппаратные требования](#аппаратные-требования)
4. [Установка на Raspberry Pi OS](#установка-на-raspberry-pi-os)
5. [Подключение ESP32 + OLED](#подключение-esp32--oled)
6. [Присутствие и слежение за лицом](#присутствие-и-слежение-за-лицом)
7. [Система эмоций](#система-эмоций)
8. [Прошивка для M5Stack Core ESP32](#прошивка-для-m5stack-core-esp32)
9. [Разработка своих скиллов](#разработка-своих-скиллов)
10. [Roadmap и дальнейшее развитие](#roadmap-и-дальнейшее-развитие)
11. [Лицензия](#лицензия)

---

## Возможности

* Активация по ключевой фразе «Джарвис» (Vosk)
* Полностью офлайн STT на основе Vosk (`model_small`)
* Приветственный звук при запуске (категория `WAKE` в `audio/sfx_manifest.yaml`)
* Натуральный TTS Piper-TTS с разбиением по 180 символам
* Горячая перезагрузка скиллов из `/skills` через `jarvis_skills.py`
* Fuzzy-распознавание команд (RapidFuzz)
* Система эмоций и событийный брокер
* Проактивные подсказки с выбором канала (голос / Telegram)
* Уведомления: озвучивание очереди сообщений и личные Telegram‑уведомления
* Вывод состояния (время, погода, произвольные тексты) на OLED-дисплей через ESP32 по Serial
* Надёжный драйвер Serial для M5Stack: фильтрация шумного JSON и автоматическое восстановление соединения
* Наблюдаемость: структурированные JSON‑логи с `trace_id` и простые метрики (`tts.queue_len`, `telegram.failures`)
* Определение присутствия пользователя и поворот камеры по веб‑камере
* Хранение событий, сессий и подсказок в SQLite (`memory/`)
* Краткосрочный и долговременный контекст (`context/`), агрегаты привычек и генератор подсказок (`analysis/`)

---

## Структура проекта

```
.
├── start.py             # основной цикл и распознавание речи
├── jarvis_skills.py     # менеджер плагинов (скиллов)
├── commands.yaml        # словарь встроенных команд
├── config.ini           # основная конфигурация ассистента
├── core/                # конфигурация, события, логирование, NLP
├── working_tts.py       # адаптер Piper-TTS
├── audio/               # звуковые эффекты и манифест (sfx_manifest.yaml)
├── context/             # краткосрочный и долгосрочный контекст
├── display/             # драйверы для вывода (console.py, serial.py, websocket.py)
├── emotion/             # система эмоций и звуковые драйверы
├── notifiers/           # уведомления (voice.py, telegram.py; публичный API `send()`)
├── sensors/             # датчики (vision/presence.py, ...)
├── proactive/           # проактивные подсказки (policy.py, engine.py)
├── analysis/            # генератор подсказок и агрегаты привычек
├── memory/              # SQLite-память событий, сессий и подсказок
├── skills/              # плагины-скиллы (time_ru.py, weather_ru.py, ...)
├── models/              # модели Vosk и Piper
├── JarvisM5/            # прошивка для M5Stack Core ESP32
├── requirements.txt
└── README.md
```

Движок уведомлений ищет модуль `notifiers.<канал>` и вызывает его
функцию `send(text)`. Таким образом можно добавить новый канал
уведомлений, реализовав одноимённую функцию в своём модуле.

---

## Аппаратные требования

| Компонент |          Минимум         |        Рекомендовано       |
| :-------: | :----------------------: | :------------------------: |
|    SBC    |   Raspberry Pi 5 (8 GB)  |    + активное охлаждение   |
|  Питание  |          5 V 3 A         |  Power-bank 5 V 20000 mAh  |
|  Микрофон |       USB-гарнитура      |     ReSpeaker 2-Mic HAT    |
|  Дисплей  | ESP32 + OLED 0.96″ (I²C) | SPI IPS 1.3–2″ или HDMI 5″ |
|  Динамик  |     3.5 мм / I²S amp     |       3 Вт + mini‑amp      |

---

## Установка на Raspberry Pi OS (64‑bit)

```bash
# 1. Клонируем репозиторий
git clone https://github.com/yourname/jarvis-pi.git
cd jarvis-pi

# 2. Системные зависимости
sudo apt update
sudo apt install -y python3-pip portaudio19-dev libasound2-dev

py -3.10 -m venv venv
# 3. Python-библиотеки
pip3 install -r requirements.txt  # включает python-dotenv для чтения .env

# 4. Копируем модель Piper
mkdir -p piper && cp ru-RU-irina-medium.* piper/

# 5. Настройка конфигурации
#   Скопируйте `.env.example` в `.env` и заполните секретные значения
cp .env.example .env
#   Откройте config.ini и укажите:
#   - в секции [MIC] → `microphone_index`
#   - в секции [PRESENCE] → `camera_index` и `frame_interval_ms`
#   - при необходимости [INTEL] → `absent_after_sec`
nano config.ini

# 6. Запуск
python3 start.py
```

После установки зависимостей убедитесь, что всё работает, выполнив тесты:

```bash
pytest
```

## Параметры `config.ini`

| Секция/параметр | Описание | Рекомендации по заполнению |
|-----------------|----------|---------------------------|
| `[MIC]` `microphone_index` | индекс микрофона (`-1` для автоопределения) | оставьте `-1`, если подключён один микрофон |
| `[AUDIO]` `sample_rate` | частота дискретизации аудио | `16000` подходит для Vosk |
| `[AUDIO]` `blocksize` | размер блока при чтении из потока | увеличьте при задержках |
| `[AUDIO]` `queue_max` | максимальная длина очереди буфера | `200` обеспечивает стабильность |
| `[AUDIO]` `grammar` | набор команд для распознавания (`full`/`grammar`) | `full` — полный словарь, `grammar` — ограниченный |
| `[add_to_prompt]` `add_to_prompt` | фраза, добавляемая к системному промпту | можно изменить под ваш контекст |
| `[USER]` `name` | имя пользователя/голосового ассистента | любое удобное имя |
| `[USER]` `telegram_user_id` | ID пользователя Telegram для личных уведомлений | переменная окружения `TELEGRAM_USER_ID`, `0` отключает уведомления |
| `[INTEL]` `api_key` | API-ключ для взаимодействия с моделью ИИ | задаётся через `INTEL_API_KEY` |
| `[INTEL]` `absent_after_sec` | сколько секунд отсутствия лица считать уходом пользователя | 5–10 секунд в зависимости от камеры |
| `[TELEGRAM]` `token` | токен для Telegram-бота | переменная окружения `TELEGRAM_TOKEN` |
| `[PRESENCE]` `enabled` | включает детектор присутствия пользователя | `true` для включения, `false` чтобы отключить |
| `[PRESENCE]` `camera_index` | индекс камеры для захвата видео | `0` — первая камера; проверьте `ls /dev/video*` |
| `[PRESENCE]` `frame_interval_ms` | интервал между кадрами в миллисекундах | `500` — баланс между скоростью и нагрузкой |

---

## Подключение ESP32 + OLED

1. В Arduino IDE установите библиотеки: `ArduinoJson`, `U8g2`.
2. Подключите ESP32 к Raspberry Pi по USB и прошейте скетч из раздела ниже.
3. Jarvis автоматически открывает последовательный порт (по умолчанию `/dev/ttyUSB0`) со скоростью 921600 бит/с.
4. Скетч должен читать строки JSON из Serial и отображать их на OLED.

При старте в Serial Monitor увидите:

```
[SER] connected
```

— сразу же на OLED отобразится текущее время, погода и актуальный текст.

---

## Присутствие и слежение за лицом

Jarvis использует системный модуль `sensors/vision/presence.py`, который:

* применяет OpenCV и MediaPipe для поиска лица, а при его отсутствии оценивает положение головы по ключевым точкам Pose;
* сглаживает уверенность методом EMA и публикует событие `presence.update` при смене состояния;
* управляет поворотом камеры и при длительном отсутствии лица инициирует поисковое сканирование.

---

## Система эмоций

> Полностью модульная, декомпозирована на **manager ↔ state ↔ driver**.

### 1. `emotion/state.py`

* Перечисление `Emotion` (`NEUTRAL`, `HAPPY`, `THINKING`, `ANGRY`, `SAD`, …)
* Таблица «idle‑эмоций» и их весов

### 2. `emotion/manager.py`

* Синглтон‑класс, подписывается на события `events.broker`
* Алгоритм:

  * при простое каждые *N* секунд публикует новую эмоцию из idle‑списка
  * на `user_query_started` → `THINKING`
  * на `user_query_ended`   → пауза 1 с → новую idle‑эмоцию

### 3. `emotion/drivers.py`

* **EmotionDisplayDriver** — адаптер к `display`‑слою: переводит `Emotion → DisplayItem(kind="emotion")` и отправляет кадры через выбранный драйвер (по Serial).

Такое разделение позволяет в будущем:

* добавлять датчики (температура, освещённость, столкновение) — просто публикуем событие → manager сам решит, какую эмоцию поставить
* заменить драйвер глазами на TFT или гэросток — достаточно другой driver‑класс

### 4. Серийный API для скиллов

Любой python‑скилл может переключить эмоцию:

```python
from emotion import publish_emotion
publish_emotion(Emotion.HAPPY)
```

---

## Прошивка для M5Stack Core ESP32

В каталоге `JarvisM5/` лежит C++17‑прошивка для **M5Stack Core ESP32**. Она показывает время,
погоду, произвольный текст и 18 эмоций, получая кадры от Jarvis по WebSocket.

Быстрый старт:

```bash
cd JarvisM5
# задайте Wi‑Fi и адрес сервера в include/Config.h
pio run -t upload
pio device monitor
```

После подключения можно отправить тестовый кадр:

```json
{"kind":"emotion","payload":"Glee"}
```

---

## Разработка своих скиллов

В папке `/skills` создайте Python-файл:

```python
PATTERNS = ["привет", "здравствуй"]
def handle(text: str) -> str:
    return "Привет, создатель!"
```

Скилл автоматически подхватится и будет вызываться по fuzzy-совпадению.

---

## Roadmap и лицензия

* v0.5: ESP32 + OLED по Serial
* v1.0: ROS, indoor SLAM

**MIT License**.
