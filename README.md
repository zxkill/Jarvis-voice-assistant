# Jarvis-Pi — голосовой ассистент и «мозг» для персонального робота

> Русскоязычный оффлайн-ассистент, голосовой коуч и персональный ассистент с горячей перезагрузкой плагинов, поддержкой локальной LLM через Ollama, выводом состояния на OLED через ESP32 по USB‑Serial и расширяемым фреймворком скиллов.

---

## Содержание

1. [Возможности](#возможности)
2. [Структура проекта](#структура-проекта)
3. [Аппаратные требования](#аппаратные-требования)
4. [Установка на Raspberry Pi OS](#установка-на-raspberry-pi-os)
5. [Подключение ESP32 + OLED](#подключение-esp32--oled)
6. [Присутствие и слежение за лицом](#присутствие-и-слежение-за-лицом)
7. [Система эмоций](#система-эмоций)
8. [Звуковые эмоции](#звуковые-эмоции)
9. [Эмоциональная речь](#эмоциональная-речь)
10. [Small-talk и проактивное общение](#small-talk-и-проактивное-общение)
11. [Диалоговые подсказки и персонализация](#диалоговые-подсказки-и-персонализация)
12. [Управление Jarvis через Telegram](#управление-jarvis-через-telegram)
13. [Прошивка для M5Stack Core ESP32](#прошивка-для-m5stack-core-esp32)
14. [Разработка своих скиллов](#разработка-своих-скиллов)
15. [Метрики](#метрики)
16. [Roadmap и лицензия](#roadmap-и-лицензия)

---

## Возможности

* Активация по ключевой фразе «Джарвис» (Vosk)
* Кольцевой аудиобуфер ~1.5 с для точного распознавания первого слова
* Полностью офлайн STT на основе Vosk (`model_small`)
* Приветственный звук при запуске (категория `WAKE` в `audio/sfx_manifest.yaml`)
* Натуральный TTS Piper-TTS с разбиением по 180 символам
* Горячая перезагрузка скиллов из `/skills` через `jarvis_skills.py`
* Fuzzy-распознавание команд (RapidFuzz)
* Система эмоций и событийный брокер
* Политика выбора эмоции по координатам valence/arousal: иконки, TTS‑пресеты и палитры звуков
* Проактивные подсказки с выбором канала (голос / Telegram) — при отсутствии пользователя всё уйдёт в Telegram
* Адаптивная система подсказок: частота показа зависит от отзывов пользователя
* Напоминания о гидратации, перерывах для глаз и постановке дневных целей
* Ожидание ответа на подсказку с публикацией события `suggestion.response` и журналированием результата
* Простые ответы «да/нет» на подсказки разбираются отдельным модулем и не вмешиваются в обработку остальных голосовых команд
* Ответы на подсказки в Telegram подтверждаются ассистентом и сохраняются в базе (`suggestion_feedback`)
* Проактивный small-talk при длительном молчании пользователя, даже если хозяин отошёл
* Уведомления: озвучивание очереди сообщений и личные Telegram‑уведомления
* Приём текстовых команд через личные сообщения Telegram‑боту (long polling)
* Надёжная обработка команд в Telegram: обработчик выполняется в основном event loop, что гарантирует отправку ответов и запуск фоновых задач
* Команды в Telegram можно писать без слова активации «Джарвис»
* Ответы в Telegram приходят текстом — без голосовых файлов, что ускоряет общение и экономит трафик
* Вывод состояния (время, погода, произвольные тексты) на OLED-дисплей через ESP32 по Serial
* Надёжный драйвер Serial для M5Stack: восстановление потерянных скобок и кавычек в JSON, фильтрация шумного трафика, игнорирование текстовых логов, потокобезопасная запись с блокировкой и автоматическое восстановление соединения; прошивка отключает вывод логов в USB‑Serial, чтобы канал использовался только для команд
* Наблюдаемость: структурированные JSON‑логи с `trace_id` и простые метрики (`tts.queue_len`, `telegram.failures`)
* Определение присутствия пользователя и поворот камеры по веб‑камере
* Ночной режим с «тихими часами»: камера и звуки автоматически отключаются на основе статистики присутствия (по умолчанию 23:00–08:00)
* Хранение событий, сессий, подсказок и отзывов (feedback) на подсказки в SQLite (`memory/`)
* Краткосрочный и долговременный контекст (`context/`), агрегаты привычек и генератор подсказок (`analysis/`)

## Система эмоций

Эмоциональный ИИ Jarvis использует двумерную модель **valence/arousal**,
которая обновляется при событиях `presence.update`, `dialog.success`,
`dialog.failure`, `weather.update` и других факторах окружающей среды.
Модуль `emotion.policy.select` автоматически подбирает подходящую иконку,
набор звуков и пресет речи, а результат публикуется через глобальный
`core.events` в виде события `emotion_changed`.  Такая архитектура обеспечивает
реалистичную реакцию ассистента и легко расширяется под новые сценарии.

### Предварительный аудиобуфер

Jarvis хранит последние полторы секунды PCM‑кадров в кольцевом буфере. Если
слово активации «джарвис» распознано с задержкой, буфер повторно
«прокручивается» по кадрам в движок Vosk и начало команды не теряется. Флаг
однократной активации предотвращает повторные перезапуски, поэтому wake-word
не теряется даже при длительном произнесении. Такой подход повышает точность
и гарантирует, что финальный запрос содержит слово активации, делая общение
с ассистентом более естественным.

---

## Структура проекта

```
.
├── start.py             # основной цикл и распознавание речи
├── jarvis_skills.py     # менеджер плагинов (скиллов)
├── commands.yaml        # словарь встроенных команд
├── config.ini           # основная конфигурация ассистента
├── core/                # конфигурация, события, логирование, NLP
├── working_tts.py       # адаптер Piper-TTS
├── audio/               # звуковые эффекты и манифест (sfx_manifest.yaml)
├── context/             # краткосрочный и долгосрочный контекст
├── display/             # драйверы для вывода (console.py, serial.py, websocket.py)
├── emotion/             # система эмоций и звуковые драйверы
├── notifiers/           # уведомления (voice.py, telegram.py; публичный API `send()`)
├── notifiers/telegram_listener.py # приём команд из Telegram через long polling
├── sensors/             # датчики (vision/presence.py, ...)
├── proactive/           # проактивные подсказки (policy.py, engine.py)
├── analysis/            # генератор подсказок и агрегаты привычек
├── memory/              # SQLite-память событий, сессий, подсказок и отзывов
├── skills/              # плагины-скиллы (time_ru.py, weather_ru.py, ...)
├── models/              # модели Vosk и Piper
├── JarvisM5/            # прошивка для M5Stack Core ESP32
├── requirements.txt
└── README.md
```

Движок уведомлений ищет модуль `notifiers.<канал>` и вызывает его
функцию `send(text)`. Таким образом можно добавить новый канал
уведомлений, реализовав одноимённую функцию в своём модуле.  Если в
`config.ini` указан токен Telegram‑бота, слушатель long polling
запускается автоматически вместе с ассистентом и принимает текстовые
команды владельца. При желании модуль можно запустить вручную:
`python3 -m notifiers.telegram_listener`.

Слушатель long polling принимает команды от владельца и отправляет
ответы в тот же канал, откуда пришла команда: голосом или текстом в
Telegram. Дублирование голосовых уведомлений в Telegram отключено,
что снижает шум и трафик. Метрика `telegram.outgoing` фиксирует только
сообщения, отправленные в Telegram, а сетевые ошибки логируются как
предупреждения. В Telegram слово активации не требуется — можно сразу
писать нужную команду.

---

## Аппаратные требования

| Компонент |          Минимум         |        Рекомендовано       |
| :-------: | :----------------------: | :------------------------: |
|    SBC    |   Raspberry Pi 5 (8 GB)  |    + активное охлаждение   |
|  Питание  |          5 V 3 A         |  Power-bank 5 V 20000 mAh  |
|  Микрофон |       USB-гарнитура      |     ReSpeaker 2-Mic HAT    |
|  Дисплей  | ESP32 + OLED 0.96″ (I²C) | SPI IPS 1.3–2″ или HDMI 5″ |
|  Динамик  |     3.5 мм / I²S amp     |       3 Вт + mini‑amp      |

---

## Установка на Raspberry Pi OS (64‑bit)

```bash
# 1. Клонируем репозиторий
git clone https://github.com/yourname/jarvis-pi.git
cd jarvis-pi

# 2. Системные зависимости
sudo apt update
sudo apt install -y python3-pip portaudio19-dev libasound2-dev

py -3.10 -m venv venv
# 3. Python-библиотеки
pip3 install -r requirements.txt  # включает python-dotenv для чтения .env

# 4. Копируем модель Piper
mkdir -p piper && cp ru-RU-irina-medium.* piper/

# 5. Настройка конфигурации
#   Скопируйте `.env.example` в `.env` и заполните секретные значения
cp .env.example .env
#   Откройте config.ini и укажите:
#   - в секции [MIC] → `microphone_index`
#   - в секции [PRESENCE] → `camera_index` и `frame_interval_ms`
#   - при необходимости [INTEL] → `absent_after_sec`
#   - при необходимости [QUIET] → `start` и `end` для задания базового интервала «тихих часов»
nano config.ini

# 6. Запуск
python3 start.py
#   Для остановки нажмите Ctrl+C — ассистент корректно завершит все подсистемы
```

После установки зависимостей убедитесь, что всё работает, выполнив тесты:

```bash
pytest
```

## Параметры `config.ini`

| Секция/параметр | Описание | Рекомендации по заполнению |
|-----------------|----------|---------------------------|
| `[MIC]` `microphone_index` | индекс микрофона (`-1` для автоопределения) | оставьте `-1`, если подключён один микрофон |
| `[AUDIO]` `sample_rate` | частота дискретизации аудио | `16000` подходит для Vosk |
| `[AUDIO]` `blocksize` | размер блока при чтении из потока | увеличьте при задержках |
| `[AUDIO]` `queue_max` | максимальная длина очереди буфера | `200` обеспечивает стабильность |
| `[AUDIO]` `grammar` | набор команд для распознавания (`full`/`grammar`) | `full` — полный словарь, `grammar` — ограниченный |
| `[add_to_prompt]` `add_to_prompt` | фраза, добавляемая к системному промпту | можно изменить под ваш контекст |
| `[USER]` `name` | имя пользователя/голосового ассистента | любое удобное имя |
| `[USER]` `telegram_user_id` | ID пользователя Telegram для личных уведомлений | переменная окружения `TELEGRAM_USER_ID`, `0` отключает уведомления |
| `[INTEL]` `api_key` | API-ключ для взаимодействия с моделью ИИ | задаётся через `INTEL_API_KEY` |
| `[INTEL]` `absent_after_sec` | сколько секунд отсутствия лица считать уходом пользователя | 5–10 секунд в зависимости от камеры |
| `[TELEGRAM]` `token` | токен для Telegram-бота | переменная окружения `TELEGRAM_TOKEN` |
| `[PRESENCE]` `enabled` | включает детектор присутствия пользователя | `true` для включения, `false` чтобы отключить |
| `[PRESENCE]` `camera_index` | индекс камеры для захвата видео | `0` — первая камера; проверьте `ls /dev/video*` |
| `[PRESENCE]` `frame_interval_ms` | интервал между кадрами в миллисекундах | `500` — баланс между скоростью и нагрузкой |
| `[QUIET]` `start/end` | базовый интервал «тихих часов» (используется до расчёта статистики) | формат `HH:MM`, по умолчанию `23:00`–`08:00` |

---

## Подключение ESP32 + OLED

1. В Arduino IDE установите библиотеки: `ArduinoJson`, `U8g2`.
2. Подключите ESP32 к Raspberry Pi по USB и прошейте скетч из раздела ниже.
3. Jarvis автоматически открывает последовательный порт (по умолчанию `/dev/ttyUSB0`) со скоростью 921600 бит/с.
4. Скетч должен читать строки JSON из Serial и отображать их на OLED.

При старте в Serial Monitor увидите:

```
[SER] connected
```

— сразу же на OLED отобразится текущее время, погода и актуальный текст.

---

## Присутствие и слежение за лицом

Jarvis использует системный модуль `sensors/vision/presence.py`, который:

* применяет OpenCV и MediaPipe для поиска лица, а при его отсутствии оценивает положение головы по ключевым точкам Pose;
* сглаживает уверенность методом EMA и публикует событие `presence.update` при смене состояния;
* управляет поворотом камеры и при длительном отсутствии лица инициирует поисковое сканирование.

### Медленный обзор комнаты

Если лицо не обнаруживается несколько секунд, камера начинает **медленно** осматривать пространство. Скорость горизонтального движения задаётся константой `SCAN_SPEED_PX_PER_SEC` в `sensors/vision/presence.py` и по умолчанию составляет 15 пикселей/сек. Увеличьте её при необходимости более быстрого обзора.

Камера совершает **циклический поворот туда‑сюда** с короткими паузами на краях, что позволяет неоднократно сканировать комнату и повышает шанс обнаружить человека. Алгоритм использует приращения по горизонтали, поэтому серва сразу меняет направление и не «залипает» на одной стороне. Для корректной работы убедитесь, что подключён серводрайвер M5Stack (`display/drivers/serial.py`) и активирован модуль `presence`.

---

## Система эмоций

> Полностью модульная, декомпозирована на **manager ↔ state ↔ driver**.

### 1. `emotion/state.py`

* Перечисление `Emotion` (`NEUTRAL`, `HAPPY`, `THINKING`, `ANGRY`, `SAD`, …)
* Таблица «idle‑эмоций» и их весов

### 2. `emotion/manager.py`

* Синглтон‑класс, подписывается на события `events.broker`
* Алгоритм:

  * при простое каждые *N* секунд публикует новую эмоцию из idle‑списка
  * на `user_query_started` → `THINKING`
  * на `user_query_ended`   → пауза 1 с → новую idle‑эмоцию

#### Динамическое настроение

* Утром ассистент выглядит сонным и может «зевнуть»
* Днём демонстрирует радость при появлении пользователя
* Поздно вечером показывает усталость отдельной иконкой ``Tired``,
  добавленной в прошивку M5Stack
  добавленной в прошивку M5Stack

Кроме базовой смены эмоций в ``EmotionState`` ведётся числовой уровень
настроения от −100 до 100.  Успешные команды повышают значение и заставляют
Jarvis чаще показывать ``HAPPY`` и другие позитивные эмоции.  Ошибки или
непонятые запросы снижают настроение, и на экране появляется ``FRUSTRATED``.
Значение хранится в SQLite и восстанавливается при следующем запуске, поэтому
поведение пользователя напрямую влияет на «характер» ассистента.

Для более тонкой эмоциональной модели реализован отдельный модуль ``emotion/mood.py``.
Он оперирует координатами ``valence/arousal`` (удовольствие/активация) и
использует конфигурацию ``config/affect.yaml``. Настроение сохраняется в SQLite,
обновления сглаживаются EMA, а все операции логируются в JSON с ``trace_id`` для
удобной трассировки.

На основе этих координат модуль ``emotion/policy.py`` подбирает визуальные и
звуковые атрибуты персонажа.  Функция ``select(valence, arousal)`` возвращает
иконку, TTS‑пресет и палитру SFX.  Встроена защита от слишком частой смены
иконок и подробное логирование выбора зоны настроения.

Таймер простоя автоматически выбирает новую эмоцию, если человек
присутствует, но не задаёт вопросов. Это делает поведение Jarvis более
живым и привлекает внимание пользователей, ищущих «динамический
голосовой ассистент».

### 3. `emotion/drivers.py`

* **EmotionDisplayDriver** — адаптер к `display`‑слою: переводит `Emotion → DisplayItem(kind="emotion")` и отправляет кадры через выбранный драйвер (по Serial).

Такое разделение позволяет в будущем:

* добавлять датчики (температура, освещённость, столкновение) — просто публикуем событие → manager сам решит, какую эмоцию поставить
* заменить драйвер глазами на TFT или гэросток — достаточно другой driver‑класс

### 4. Серийный API для скиллов

Любой python‑скилл может переключить эмоцию:

```python
from emotion import publish_emotion
publish_emotion(Emotion.HAPPY)
```

## Звуковые эмоции

Jarvis поддерживает **звуковые эмоции** — короткие эффекты, которые
оживляют реакции ассистента. Подключение происходит через файл
`audio/sfx_manifest.yaml`, где описываются категории и пути к WAV‑файлам.

### Как подключить

1. Скопируйте или создайте нужные WAV‑файлы и пропишите их в манифесте.
   Доступные категории: `IDLE_BREATH`, `WAKE`, `YAWN`, `SIGH`.
2. Запустите ассистент — драйвер автоматически подхватит новые эффекты.
3. Для каждого эффекта можно задать паузу `cooldown_ms` и количество
   повторов `repeat` (по умолчанию `1`).  Функция `play_effect`
   учитывает эти параметры, не давая одному и тому же звуку звучать
   чаще разрешённого интервала и повторяя его ровно заданное число раз.

### Примеры использования

```python
import emotion.sounds as sounds

sounds.play_effect("WAKE")          # приветствие при старте
driver = sounds.EmotionSoundDriver()
driver.play_idle_effect()            # тихое «дыхание» в простое
```

При появлении человека в кадре драйвер прекращает воспроизведение
«дыхания», чтобы ассистент не «вздыхал» при виде собеседника.

По умолчанию короткое дыхание воспроизводится не чаще одного раза в 15 минут,
что избавляет пользователя от навязчивых повторов и делает поведение
ассистента более естественным.  Таймер перезапускается при каждом появлении
человека или смене эмоции, поэтому звук не воспроизводится, пока ассистент
общается с пользователем.  Даже при одновременном запуске нескольких
экземпляров драйвера глобальный счётчик препятствует повтору чаще
допустимого интервала.

Встроенные блокировки и таймауты предотвращают повтор звуковых эффектов,
а параметр `repeat` по умолчанию воспроизводит `IDLE_BREATH` ровно один
раз. Поэтому типичные проблемы вроде «звук дыхания повторяется пять раз
подряд» теперь исключены и по запросу «повтор звука дыхания Jarvis» легко
найти решение.

Каждое воспроизведение фиксируется в журнале с указанием эффекта и
функции, инициировавшей звук.  В логах легко увидеть сообщения вида
`play WAKE (wake.wav) by start.startup`, что ускоряет поиск лишних
вызовов и делает отладку прозрачной.

Звуковые эмоции повышают вовлечённость и SEO‑дружелюбно упоминаются в
этом разделе, поэтому запросы вроде «звук эмоции Jarvis» легко находят
репозиторий.

---

## Эмоциональная речь

Jarvis умеет воспроизводить **эмоциональную речь**: высота голоса и
скорость варьируются в зависимости от настроения персонажа.  Это делает
диалоги более естественными и привлекает пользователей, ищущих в сети
"эмоциональный TTS" или "настройка pitch speed".

### Быстрый старт

1. Передайте эмоцию при озвучивании:

   ```python
   import notifiers.voice as voice
   voice.send("Привет!", emotion="happy")
   ```

2. Тон и скорость можно задавать напрямую:

   ```python
   voice.send("Говорю медленно", pitch=0.9, speed=0.8)
   ```

3. Список доступных пресетов и их параметры хранится в
   `working_tts.py` в словаре `TTS_PRESETS` — меняйте значения под свои
   задачи.

Подробное логирование в `working_tts.py` поможет подобрать оптимальные
параметры: в логах выводятся выбранная эмоция, `pitch`, `speed` и
длительность озвучки.

---

## Small-talk и проактивное общение

Jarvis начинает разговор при длительном молчании: рядом ли вы или ушли по делам,
он всё равно напомнит о себе. Если пользователь присутствует, фраза
озвучивается, а при отсутствии отправляется в личный Telegram. Короткие
реплики вроде «Как дела?» или «Пора размяться!» создают ощущение живого диалога.

После каждой подсказки ассистент ожидает ответ (`да`/`нет` и т.п.) в течение
нескольких секунд и публикует событие `suggestion.response`, что помогает
анализировать реакцию пользователя и улучшать рекомендации. На основе собранных
отзывов Jarvis автоматически снижает частоту надоедливых подсказок и чаще
предлагает те, что пользователь принимает.

### Примеры сценариев

* В рабочее время ассистент напоминает сделать перерыв и размять мышцы.
* Периодически напоминает попить воды и дать глазам отдохнуть от экрана.
* Утром помогает сформулировать и отслеживать ежедневные цели.
* На выходных бот заводит короткий разговор, чтобы создать дружественную атмосферу.

Функция small-talk полностью офлайн и легко настраивается.

## Диалоговые подсказки и персонализация

Jarvis выступает как голосовой коуч и персональный ассистент: он даёт диалоговые подсказки и проактивные напоминания, а ответы пользователя сохраняются в базе `memory/memory.sqlite3`. На их основе ассистент уточняет частоту подсказок и подстраивается под привычки владельца. Ответить на подсказку можно голосом или сообщением в Telegram — ассистент пришлёт короткое подтверждение и запишет ответ для дальнейшего анализа.

#### Настройка

* Включите подсказки в `config.ini` параметром `proactive.enabled = true`.
* База данных создаётся автоматически в `memory/`; для сброса удалите файл `jarvis.db`.
* Команды и скиллы добавляются в `commands.yaml` или как новые модули в каталоге `skills/`.

---

## Управление Jarvis через Telegram

Jarvis Telegram бот помогает контролировать голосовой ассистент на Raspberry Pi удалённо: уведомления приходят лично, команды выполняются, ответы возвращаются текстом.

Обработчик Telegram-запросов запускается в основном event loop ассистента, поэтому фоновые задачи (озвучивание, метрики) не теряются и ответы всегда доходят до пользователя.
Чтобы откликнуться на подсказку, отправьте боту сообщение «да» или «нет» — Jarvis подтвердит получение и сохранит результат в базе.

### Настройка

1. Зарегистрируйте бота через @BotFather и узнайте свой ID (`@userinfobot`).
2. Заполните `.env` (пример в `.env.example`):

```env
TELEGRAM_TOKEN=123456:ABCDEF
TELEGRAM_USER_ID=987654321
```

3. Установите зависимость:

```bash
pip install requests  # или python-telegram-bot
```

### Запуск

Слушатель Telegram включается автоматически при запуске Jarvis, либо вручную:

```bash
python -m notifiers.telegram_listener
```

---

## Прошивка для M5Stack Core ESP32

В каталоге `JarvisM5/` лежит C++17‑прошивка для **M5Stack Core ESP32**. Она показывает время,
погоду, произвольный текст и 19 эмоций (включая новую ``Tired``), получая кадры от Jarvis по WebSocket.

Быстрый старт:

```bash
cd JarvisM5
# задайте Wi‑Fi и адрес сервера в include/Config.h
pio run -t upload
pio device monitor
```

После подключения можно отправить тестовый кадр:

```json
{"kind":"emotion","payload":"Glee"}
```

По умолчанию прошивка не выводит диагностические сообщения в USB‑Serial.
Для отладки их можно включить командой:

```json
{"kind":"log","payload":"on"}
```

---

## Разработка своих скиллов

В папке `/skills` создайте Python-файл:

```python
PATTERNS = ["привет", "здравствуй"]
def handle(text: str) -> str:
    return "Привет, создатель!"
```

Скилл автоматически подхватится и будет вызываться по fuzzy-совпадению.

---

## Метрики

Jarvis ведёт счётчики для мониторинга производительности и UX. Метрики
доступны через модуль `core.metrics` и могут быть экспортированы внешней
системой мониторинга.

- `tts.queue_len` — длина очереди TTS, помогает отслеживать задержки озвучки
- `telegram.failures` — количество ошибок отправки сообщений в Telegram
- `suggestions.queued` — сколько подсказок поставлено в очередь
- `suggestions.sent` и `suggestions.failed` — успешные и неудачные отправки
- `suggestions.responded` — получено ответов от пользователя
- `suggestions.accepted` и `suggestions.declined` — положительные и отрицательные ответы

---

## Roadmap и лицензия

* v0.5: ESP32 + OLED по Serial
* v1.0: ROS, indoor SLAM

**MIT License**.
